{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broken-brisbane",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# COGS 18 - Final Exam\n",
    "\n",
    "This is the practice final exam for Winter 2022. It covers topics through the end of the course.\n",
    "\n",
    "This exam is out of 0 points, but the real thing will be out of 19 points, worth 19% of your grade. \n",
    "\n",
    "**PLEASE DO NOT CHANGE THE NAME OF THIS FILE.**\n",
    "\n",
    "**PLEASE DO NOT COPY & PASTE OR DELETE CELLS INLCUDED IN THE EXAM.** (Note that you can add additional cells, if you want to test things out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-fraud",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0bdbfd4b5b7050f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Instructions\n",
    "|\n",
    "#### Timing\n",
    "- The exam is designed to take you ~2-3h.\n",
    "- If it takes you longer than 3h, you're free to use that time.\n",
    "\n",
    "#### The Rules\n",
    "- You are to complete this exam on your own.\n",
    "- This is open-notes & open-Google\n",
    "- You may not talk to any humans about this exam. \n",
    "- The following are all *prohibited*:\n",
    "    - text/phone/online chat communication\n",
    "    - posting questions to a message board where a human could respond (Campuswire, Discord, Chegg, any similar site)\n",
    "    - viewing exam questions from a message board (as described above)\n",
    "    - asking anyone via any form about a question on this test directly\n",
    "- Clarification questions will ***not*** be allowed and there will be no posting on Campuswire about the exam at all. \n",
    "    - Campuswire posts about the exam will not be answered and will be deleted. \n",
    "    - Students who post questions about the exam to Campuswire are at risk of losing points on the exam.\n",
    "    - If you are confused about wording, add a note to your exam explaining your confusion and how you interpreted the question. \n",
    "    - Note: This policy is b/c we are incapable of responding for 48+ hours straight. This is the only way to make it fair across the board for students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-story",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-516057c92936dcb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " <span style=\"color: red;\">Note: </span> There _is_ a chance for partial credit on some questions, so _some_ code is better than _no_ code. Even if it throws an error, having some code that partially answers the question will benefit you/your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-string",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65babcd260f10212",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q0 - Honor Code\n",
    "\n",
    "In the cell below, include a variable `honor_code` that stores the boolean `True` if you agree to the following statement:\n",
    "\n",
    ">I agree that this exam was completed individually with the knowlege in my brain, information the notes from this course, and/or with searching for help on the Internet *without searching for answers to the text from these questions directly*. I did not ask anyone about specific questions on this exam. I did not post these questions (in part or in whole) on the Internet. I did not copy answers to these questions from anywhere or anyone else. I understand all code I've written on this exam and could explain my answers to someone else if asked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "golden-healing",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c43003780d414c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "honor_code = True\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "signed-garage",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2fa97174501cfae8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert honor_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-wilson",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a5d75a30bb1182",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Project Intro\n",
    "\n",
    "In this project, you'll be working with data collected by questionnaire that looked to better undersatnd Student Time Management.\n",
    "\n",
    "While there are many questions one *could* ask about this dataset, we're going to focus on the following question:\n",
    "\n",
    "> Does gender affect whether someone is more likely to leave soemthing to the last minute?\n",
    "\n",
    "While everything you need has been provided in the final folder, if you're interested, more information about these data can be read [on kaggle](https://www.kaggle.com/xiaowenlimarketing/international-student-time-management)\n",
    "\n",
    "*Caveat*: In these data, data from only two genders are represented (males, females); however, gender is not binary and a better dataset would be more reflective of this fact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-cornwall",
   "metadata": {},
   "source": [
    "### Files Included\n",
    "\n",
    "There are 5 files included in your Project folder. Each is described below:\n",
    "\n",
    "- `Final.ipynb` | this notebook file; includes exam instructions\n",
    "- `time_manageement.py` | module that will store your functions (has a single function in it to start)\n",
    "- `test_time_management.py` | test file (has a single test function to start)\n",
    "- `International students Time management data.csv` | data file with the data we'll be using for the analayis\n",
    "- `testfile.csv` | a smaller version of the data file that can be used for testing\n",
    "\n",
    "**Do not move or change the name of any of these files.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-airfare",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16901a78cdbb3c8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 1: Code +  (11 pts)\n",
    "\n",
    "In this section, you'll write the functions needed to carry out the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-productivity",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b19f542694e258b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1: function: `read_data` (3 pts)\n",
    "\n",
    "Define a function `read_data` with a single parameter `file` that accomplishes the following, using `pandas` functions/methods:\n",
    "\n",
    "1. uses `pandas` to read the `file` in\n",
    "2. extracts only two of the columns: `'Gender'` and `'11'`\n",
    "3. Renames these two columns to have the column names `'gender'` and `'last_minute'`\n",
    "4. `return`s the resulting data frame from the function.\n",
    "\n",
    "Notes:\n",
    "- column '11' from the original dataset are respondent's response on the questionnaire to the statement 'You tend to leave things to the last minute'\n",
    "- to test out your function here, you'll need to `import pandas as pd` first (outside your function).\n",
    "\n",
    "**Suggested smoke test**: Executing the function as follows: `read_data(file = 'testfile.csv')` should return a `pandas` DataFrame with two columns and 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "popular-advocacy",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a00bd145029f997",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "\n",
    "def read_data(file):\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['Gender', '11']]\n",
    "    df.columns = ['gender', 'last_minute']\n",
    "    \n",
    "    return df\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "weird-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BE SURE YOUR ANSWER IS IN THE CELL ABOVE\n",
    "# but you can use this cell to test/execute/check your thinking (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "charming-russian",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1d31bb00de367f31",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert read_data\n",
    "### BEGIN HIDDEN TESTS\n",
    "import pandas as pd\n",
    "df = read_data('testfile.csv')\n",
    "assert isinstance(df, pd.DataFrame)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hollywood-tradition",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-27ab0369eac92b75",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check correct output shape\n",
    "### BEGIN HIDDEN TESTS\n",
    "# check extracted columns correctly\n",
    "assert df.shape == (10, 2)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "precious-medicaid",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-460c72010bbad8f5",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check correct column names\n",
    "### BEGIN HIDDEN TESTS\n",
    "# check columns renamed correctly\n",
    "assert list(df.columns) == ['gender', 'last_minute']\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-oriental",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-727a4fb9129b4554",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "If points lost above, check for partial credit (otherwise, give full credit):\n",
    "- function defined correctly with `data` parameter (**0.2 pts**)\n",
    "- reads file in correctly using `pd.read_csv()` function (**0.25 pts**)\n",
    "- selects columns correctly (**0.5 pts**)\n",
    "- renames columns correctly (**0.5 pts**)\n",
    "- includes `return` statement (**0.05 pts**)\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-circumstances",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e2ab314a409f5570",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2: function: `calculate_stats` (3 pts)\n",
    "\n",
    "Now, define a function `calculate_stats` that takes in two parameters `df` (the DataFrame it will operate on) and `label` (the value in the column that we want to extract -will be either 'M' or 'F' upon execution). \n",
    "\n",
    "This function should:\n",
    "1. Filter to only include those values from the `'gender'` column in `df` that are exactly equal to `label`\n",
    "2. Calculate `value_counts()` on the `'last_minute` column of the dataframe generated in step 1 above, using the `normalize=True` parameter in the `value_counts()` method\n",
    "3. `return`s the results from step 2 from the function\n",
    "\n",
    "**Suggested smoke tests**: Executing the function as follows (where `df` is the output after having run `read_data()` on 'testfile.csv'): `calculate_stats(df, 'M')` should return:\n",
    "\n",
    "```\n",
    "Neither    0.6\n",
    "Agree      0.4\n",
    "Name: last_minute, dtype: float64\n",
    "```\n",
    "\n",
    "and `calculate_stats(df, 'F')` should return:\n",
    "\n",
    "```\n",
    "Strong Agree    0.4\n",
    "Disagree        0.4\n",
    "Agree           0.2\n",
    "Name: last_minute, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "organic-ebony",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-afa8d458aebc68a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def calculate_stats(df, label):\n",
    "    \n",
    "    df = df[df['gender'] == label]\n",
    "    val_counts = df['last_minute'].value_counts(normalize=True)\n",
    "    \n",
    "    return val_counts\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "found-omega",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-aefae4ed66a24acc",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check function executes without error\n",
    "### BEGIN HIDDEN TESTS\n",
    "df = read_data('testfile.csv')\n",
    "out_M = calculate_stats(df, 'M') \n",
    "out_F = calculate_stats(df, 'F')\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exact-living",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-65155f89eb909bfb",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check output is of correct type\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert isinstance(out_M, pd.Series)\n",
    "assert isinstance(out_F, pd.Series)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "parental-arbor",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2b38fb1aeaf6bb97",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check check categories are correct\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert list(out_M.index) == ['Neither', 'Agree']\n",
    "assert list(out_F.index) == ['Disagree', 'Strong Agree', 'Agree']\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "younger-criminal",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-14ba1f3c9aed3938",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test to check check values are correct\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert list(out_M.values) == [0.6, 0.4]\n",
    "assert list(out_F.values) == [0.4, 0.4, 0.2]\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-bulgaria",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0c76fe9aa784dc0",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "If points lost above, check for partial credit (otherwise, give full credit):\n",
    "- function defined correctly with parameters `df` amd `label` (**0.25 pts**)\n",
    "- conditional filtering correct (**0.5 pts**)\n",
    "- value_counts() syntax correct; specifies `normalize=True` parameter (**0.5 pts**)\n",
    "- `return` statement included (**0.25 pts**)\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-insulin",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99b75634429b425b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3: module `time_management.py` (5 pts)\n",
    "\n",
    "Here, we'll move your functions from Part 1 into our `time_management` module and get that module all ready to go!\n",
    "\n",
    "`time_management.py` has three `import` statements at the top and a single function `generate_plot`. The code in `generate_plot` functions; however, you'll notice that the code style is poor. You'll fix that in just a second!\n",
    "\n",
    "To make this module more complete and polished, carry out the following steps:\n",
    "\n",
    "1. Copy the `read_data` and `calculate_stats` functions from Q1 and Q2 (respectively) into the `time_management` module (the module will have three functions total, including `generate_plot`)\n",
    "2. Edit all three functions for Code Style, as discussed in class\n",
    "3. Add helpful code comments throughout all three functions\n",
    "4. Add `numpy` style docs to all three functions, as discussed in class\n",
    "\n",
    "Note: Nothing has to be done in the notebook for this question. Everything will happen in `time_management.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-raise",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11ebcb4b45937698",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "To grade, you'll have to open up this student's `time_management.py` file:\n",
    "- contains 3 functions (**0.5 pts**)\n",
    "- all three functions have good code style (line spacing, spacing around operators, good variable names, etc.) (**1.5 pts**)\n",
    "- functions contain at least some level of helpful code comments (**1 pts**)\n",
    "- functions contain `numpy` style docstrings, specifying one-liner, Parameters, and Returns (**2 pts**)\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-liberia",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-691e6e62f44e642b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2: Code Testing (4.5 pts)\n",
    "\n",
    "At this point, you've got three well-documented functions with helpful code comments and good code style in `time_management.py`. Now it's time to focus on our code tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-injury",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a0e38ca05197c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4: test function: `test_calculate_stats` (1.5 pts)\n",
    "\n",
    "`test_calculate_stats` has been provided for you. Describe in the cell below what exactly this test function is accomplishing/testing. (This will likely include an explanation of each line of code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "congressional-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEEL FREE TO USE THIS CELL TO CHECK YOUR UNDERSTANDING (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-horizontal",
   "metadata": {},
   "source": [
    "***Replace this with your explanation.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-sleeping",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2b026b00252f52c",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "- overall explanation of the test function/what a test function is is close to right (**0.25 pts**)\n",
    "- describes dummy DataFrame creation (**0.25 pts**)\n",
    "\n",
    "the following four could explain either/both the M/F versions\n",
    "- correctly explains that `out_M = calculate_stats(df, 'M')` is executing the function (**0.25 pts**)\n",
    "- explains that `assert isinstance(out_M, pd.Series)` is checking the output type (**0.25 pts**)\n",
    "- explains that `assert list(out_M.index) == ['Neither', 'Agree']` is the categories from the original datframe (**0.25 pts**)\n",
    "- explains that `assert list(out_M.values) == [0.6, 0.4]` are the proportions of how often the value shows up (**0.25 pts**)\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-beverage",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a66a47ceca428493",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5: test function: `test_read_data` (3 pts)\n",
    "\n",
    "Now it's your turn to write your own test function. Add a test function `test_read_data()` to `test_time_management.py` that 1) includes at least three `assert` statements and 2) tests the functionality of the `read_data` function. \n",
    "\n",
    "Be sure to also include the necessary `import` statements at the top of the test file.\n",
    "\n",
    "Notes:\n",
    "- this will likely use the `'testfile.csv'` file provided\n",
    "- nothing has to be done in the notebook here; however, feel free to test out your work below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suspended-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEEL FREE TO USE THIS CELL TO CHECK YOUR UNDERSTANDING (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-thong",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-56d1302cffeb086b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "To grade, you'll have to open up this student's `test_time_management.py` file:\n",
    "\n",
    "- `import` statement included (**0.5 pts**)\n",
    "- `import` statement matches how used in tests (**0.5 pts**)\n",
    "- `test_read_data()` has at least 3 `assert`s  (**0.5 pts**)\n",
    "- `assert`s test functionality of the code (i.e. type of, shape of, columns in, and/or values in output) (**1.5 pts**)\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-christmas",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ceec5737e8b0e0ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q6: `pytest` (2 pts)\n",
    "\n",
    "In the cell below, execute `pytest` on your test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "thick-harmony",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-289115be2870f53e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
      "rootdir: /Users/shannonellis/Desktop/Teaching/COGS18/Exams/Fa21/source/Practice_Final_answer\n",
      "plugins: anyio-3.3.0\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_time_management.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.23s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "!pytest test_time_management.py\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "greek-while",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-87fa8c6fd9817fc0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test running pytest\n",
    "### BEGIN HIDDEN TESTS\n",
    "out = !pytest test_time_management.py\n",
    "assert out.grep(\"ERRORS\") == []\n",
    "assert out.grep(\"FAILED\") == []\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-territory",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b701d7378262d41",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "- syntax calling `pytest` correct (even if tests failed) (**1 pt**) \n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-enzyme",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4fc1b11741335db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 3: `import` (+ use) (1.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-rabbit",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e2c2e62ece0dfde0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q7: module import (1.5 pts)\n",
    "\n",
    "At this point you have a module with three functions and a test file with two functions, on which you've (hopefully successfully) executed `pytest` and have passing tests.\n",
    "\n",
    "Now, it's time to put it all together and use it!\n",
    "\n",
    "Below, `import` your `time_management` module below, so that when I execute you execute the four cells with code provided below, they execute without error, with the final cell producing a plot of your data.\n",
    "\n",
    "Note: You will likely need to restart your kernel before the `import` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "difficult-relaxation",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a74fbd0ae9141f54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import time_management as tm\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-northern",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36d2b37a342fb65a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**This \"blank\" cell included intentionally.** Do not do anything here. (It's being used in grading.)\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "- `import time_management as tm` syntax correct; even if it produces an error, give full credit (**0.5 pts**)\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "clinical-prophet",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b11bf0bb5d80ec8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# execute read_data function\n",
    "df = tm.read_data(file = 'International students Time management data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "genuine-carbon",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ef7e34cef8de3ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neither            0.338710\n",
       "Disagree           0.274194\n",
       "Agree              0.258065\n",
       "Strong Disagree    0.064516\n",
       "Strong Agree       0.064516\n",
       "Name: last_minute, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute calculate_stats function\n",
    "tm.calculate_stats(df, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "standing-mission",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d77ef8aa26ca6225",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disagree           0.311475\n",
       "Agree              0.245902\n",
       "Neither            0.213115\n",
       "Strong Disagree    0.147541\n",
       "Strong Agree       0.081967\n",
       "Name: last_minute, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute calculate_stats function\n",
    "tm.calculate_stats(df, 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "three-underwear",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-feb9e9b37a07fe75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# produce a plot\n",
    "out = tm.generate_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sorted-evening",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9e11c09f4c6be5d2",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tm.read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "floppy-headset",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a927fadd81a1f911",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tm.calculate_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "interested-continent",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7709824a82974bad",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tm.generate_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "decimal-frequency",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b211324399c9c5c1",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that plot was generated\n",
    "### BEGIN HIDDEN TESTS\n",
    "import matplotlib.pyplot as plt\n",
    "assert isinstance(out, plt.Figure)\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
